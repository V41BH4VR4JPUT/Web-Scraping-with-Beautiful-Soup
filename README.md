# Web Scraping with BeautifulSoup ğŸ•¸ï¸

This repository contains beginner-friendly yet practical examples of web scraping using **Python** and the **BeautifulSoup** library. The goal is to learn how to extract useful information from webpages and understand the structure of HTML and how to navigate it with Python.

---

## ğŸ“ Directory Structure

```
v41bh4vr4jput-web-scraping-with-beautiful-soup/
â”œâ”€â”€ blog_explorer.py          # Scrapes blog post data (e.g., titles, links)
â”œâ”€â”€ LEARNING_LOG.md           # Notes and learning progress
â”œâ”€â”€ requirement.txt           # Python dependencies
â””â”€â”€ wiki_scrapper.py          # Scrapes content from Wikipedia pages
```

---

## ğŸŒ Project Overview

This repository demonstrates how to:

* Send HTTP requests using `requests`
* Parse and navigate HTML using `BeautifulSoup`
* Extract specific HTML tags and attributes
* Store or display scraped data

These scripts serve as foundational tools for automating data collection from the web, which is useful in data science, journalism, business intelligence, and more.

---

## ğŸ” Scripts Description

### `blog_explorer.py`

Scrapes blog articles from a specified website. It collects:

* Blog titles
* URLs
* Possibly summaries or timestamps (customizable)

### `wiki_scrapper.py`

Scrapes information from Wikipedia pages. For example:

* Intro paragraphs
* Headings or metadata
* Page links

This is helpful for gathering content for research or creating datasets.

---

## ğŸ› ï¸ Requirements

Make sure you have Python 3 installed. Then install the dependencies:

```bash
pip install -r requirement.txt
```

---

## ğŸš€ Getting Started

Run the scripts using:

```bash
python blog_explorer.py
python wiki_scrapper.py
```

Modify the URLs in the scripts based on your target pages.

---

## ğŸ§  Learning Progress

Check out `LEARNING_LOG.md` for notes and reflections on whatâ€™s being learned throughout the journey.

---


