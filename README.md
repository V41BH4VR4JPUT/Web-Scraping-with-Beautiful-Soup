# Web Scraping with BeautifulSoup 🕸️

This repository contains beginner-friendly yet practical examples of web scraping using **Python** and the **BeautifulSoup** library. The goal is to learn how to extract useful information from webpages and understand the structure of HTML and how to navigate it with Python.

---

## 📁 Directory Structure

```
v41bh4vr4jput-web-scraping-with-beautiful-soup/
├── blog_explorer.py          # Scrapes blog post data (e.g., titles, links)
├── LEARNING_LOG.md           # Notes and learning progress
├── requirement.txt           # Python dependencies
└── wiki_scrapper.py          # Scrapes content from Wikipedia pages
```

---

## 🌐 Project Overview

This repository demonstrates how to:

* Send HTTP requests using `requests`
* Parse and navigate HTML using `BeautifulSoup`
* Extract specific HTML tags and attributes
* Store or display scraped data

These scripts serve as foundational tools for automating data collection from the web, which is useful in data science, journalism, business intelligence, and more.

---

## 🔍 Scripts Description

### `blog_explorer.py`

Scrapes blog articles from a specified website. It collects:

* Blog titles
* URLs
* Possibly summaries or timestamps (customizable)

### `wiki_scrapper.py`

Scrapes information from Wikipedia pages. For example:

* Intro paragraphs
* Headings or metadata
* Page links

This is helpful for gathering content for research or creating datasets.

---

## 🛠️ Requirements

Make sure you have Python 3 installed. Then install the dependencies:

```bash
pip install -r requirement.txt
```

---

## 🚀 Getting Started

Run the scripts using:

```bash
python blog_explorer.py
python wiki_scrapper.py
```

Modify the URLs in the scripts based on your target pages.

---

## 🧠 Learning Progress

Check out `LEARNING_LOG.md` for notes and reflections on what’s being learned throughout the journey.

---


